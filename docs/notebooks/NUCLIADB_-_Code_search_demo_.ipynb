{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21000294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "import requests\n",
    "\n",
    "from nucliadb_models.resource import KnowledgeBoxObj\n",
    "from nucliadb_sdk.client import Environment, NucliaDBClient\n",
    "from nucliadb_sdk.knowledgebox import KnowledgeBox\n",
    "from nucliadb_sdk.labels import Label\n",
    "from nucliadb_sdk.vectors import Vector\n",
    "from nucliadb_sdk.utils import create_knowledge_box,get_or_create\n",
    "from typing import Any, Dict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e307ba",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Once we've started **NucliaDB's container**\n",
    "\n",
    "``` \n",
    "docker run -it \\\n",
    "       -e LOG=INFO \\\n",
    "       -p 8080:8080 \\\n",
    "       -p 8060:8060 \\\n",
    "       -p 8040:8040 \\\n",
    "       -v nucliadb-standalone:/data \\\n",
    "       nuclia/nucliadb:latest\n",
    "```\n",
    "we'll check the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04920c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(f\"http://0.0.0.0:8080\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b42d61",
   "metadata": {},
   "source": [
    "## Setup - creating a KB\n",
    "\n",
    "In nucliadb our data containers are called knowledge boxes.\n",
    "\n",
    "To start working, we need to create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e6fcb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nucliadb_sdk.knowledgebox.KnowledgeBox at 0x15096c1c0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_kb = create_knowledge_box(\"my_code_search_kb\")\n",
    "my_kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0936ab3",
   "metadata": {},
   "source": [
    "## Data preparation  - Collection\n",
    "\n",
    "Then we gather the data. \n",
    "\n",
    "In this case we use the inspect library to gather all the functions from our nucliadb_sdk module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f397f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client\n",
      "entities\n",
      "file\n",
      "knowledgebox\n",
      "labels\n",
      "logging\n",
      "resource\n",
      "search\n",
      "utils\n",
      "vectors\n"
     ]
    }
   ],
   "source": [
    "import nucliadb_sdk\n",
    "from inspect import getmembers, isfunction, ismodule,isclass,getsource\n",
    "\n",
    "def get_all_code(target_module):\n",
    "    functions=[]\n",
    "    functions_code=[]\n",
    "    for  module_name, module in getmembers(target_module,ismodule):\n",
    "        if module_name != \"logging\":\n",
    "            functions.extend([(name,fn) for name, fn in getmembers(module, isfunction) if fn.__module__ == module.__name__])\n",
    "            for my_class_name,my_class in [(name,fn) for name, fn in getmembers(module, isclass) if fn.__module__ == module.__name__]:\n",
    "                functions.extend([(name,fn) for name, fn in getmembers(my_class, isfunction) if fn.__module__ == module.__name__ and (\"__\" not in fn.__name__)])\n",
    "    functions_code=[getsource(function) for function_name,function in functions ]\n",
    "    return functions_code\n",
    "my_functions = [i.strip() for i in get_all_code(nucliadb_sdk)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c5be1",
   "metadata": {},
   "source": [
    "Just a quick check to see how many functions we gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c415967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d6144",
   "metadata": {},
   "source": [
    "## Data preparation  - Create vectors\n",
    "\n",
    "Once we have all the code, we need to calculate the vectors.\n",
    "In this case we are using:\n",
    "\n",
    "Microsoft's unixcoder-base\n",
    "\n",
    "model_t5 = SentenceTransformer(\"krlvi/sentence-t5-base-nlpl-code_search_net\")\n",
    "\n",
    "model_bert = SentenceTransformer(\"krlvi/sentence-msmarco-bert-base-dot-v5-nlpl-code_search_net\")\n",
    "\n",
    "model_distilroberta = SentenceTransformer(\"flax-sentence-embeddings/st-codesearch-distilroberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e1c658d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "def get_vectors_roberta_pool(tokenizer, model, code_list):\n",
    "    encoded_input = tokenizer(list(code_list),padding=True, truncation=True,max_length =1024, return_tensors=\"pt\")\n",
    "    outputs = model(**encoded_input)\n",
    "    return outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "651d82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t5 = SentenceTransformer(\"krlvi/sentence-t5-base-nlpl-code_search_net\")\n",
    "model_bert = SentenceTransformer(\"krlvi/sentence-msmarco-bert-base-dot-v5-nlpl-code_search_net\")\n",
    "model_distilroberta = SentenceTransformer(\"flax-sentence-embeddings/st-codesearch-distilroberta-base\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd0161",
   "metadata": {},
   "source": [
    "## Upload our Data\n",
    "\n",
    "Now we have the data and we have created the KB (knowledgebox), so we just need to upload our resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ef46a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorset is not created, we will create it for you\n",
      "Vectorset is not created, we will create it for you\n",
      "Vectorset is not created, we will create it for you\n",
      "Vectorset is not created, we will create it for you\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(my_functions)):\n",
    "    label = \"nucliadb_sdk\"\n",
    "    my_kb.upload(\n",
    "        text=my_functions[i],\n",
    "        labels=[f\"code/{label}\"],\n",
    "        vectors={\"unixcoder-meanpooling\": get_vectors_roberta_pool(tokenizer, model,[my_functions[i]]).tolist(),\n",
    "                 \"t5\": model_t5.encode([my_functions[i]])[0].tolist(),\n",
    "                 \"bert\":  model_bert.encode([my_functions[i]])[0].tolist(),\n",
    "                 \"distilroberta\":  model_distilroberta.encode([my_functions[i]])[0].tolist(),\n",
    "                 },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e947b",
   "metadata": {},
   "source": [
    "## Checks I \n",
    "\n",
    "We uploaded only data with one label. \n",
    "\n",
    "But we could have added more if we had code from other modules, or if we wanted to label some other code features\n",
    "\n",
    "Let's check if the numbers agree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3abdee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': LabelSet(count=51, labels={'nucliadb_sdk': 51})}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_kb.get_uploaded_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1af9e",
   "metadata": {},
   "source": [
    "## Checks II\n",
    "\n",
    "We can also list all the different sets of vectors we've uploaded and their dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "df5e299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distilroberta': VectorSet(dimension=768),\n",
       " 'bert': VectorSet(dimension=768),\n",
       " 't5': VectorSet(dimension=768),\n",
       " 'unixcoder-meanpooling': VectorSet(dimension=768)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_kb.list_vectorset().vectorsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4c296",
   "metadata": {},
   "source": [
    "## Searches\n",
    "\n",
    "Now let's start with the most interesting part, the searches!\n",
    "\n",
    "We are going to use a small function to iterate over our search results.\n",
    "\n",
    "For legibility reasons I used a simple regex to print only the name of the function,\n",
    "but feel free to modify it if you want the whole code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7bf717c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_results(model_name, results):\n",
    "    print(f\"\\t***{model_name.upper()} RESULTS***\")\n",
    "    for result in results:\n",
    "        print(\"Function name:\",re.findall('def ([^\\(]+)', result.text)[0], end=\" -- \")\n",
    "        #print(\"Function code:\",'%.300s' %result.text,\"\\n\\t...\")\n",
    "        #print(\"Function labels:\",\" \".join(result.labels))\n",
    "        print(\"Similarity score:\",result.score) \n",
    "    print(\"-----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e0fbc",
   "metadata": {},
   "source": [
    "## Text search\n",
    "\n",
    "First we search only in the text fields\n",
    "\n",
    "We will look for `create_resource` and `create a new knowledge box`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "283afa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t***FULL TEXT SEARCH RESULTS***\n",
      "Function name: create_resource -- Similarity score: 3.4008634090423584\n",
      "Function name: async_create_resource -- Similarity score: 3.343503713607788\n",
      "Function name: list_resources -- Similarity score: 2.592740774154663\n",
      "Function name: async_list_resources -- Similarity score: 2.526648998260498\n",
      "Function name: upload -- Similarity score: 2.3800771236419678\n",
      "Function name: async_upload -- Similarity score: 2.3800771236419678\n",
      "Function name: create_resource -- Similarity score: 0.7249264121055603\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "results = my_kb.search(text=\"create_resource\")\n",
    "print_results(\"Full text search\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d33f78b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t***FULL TEXT SEARCH RESULTS***\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "results = my_kb.search(text=\"create a new knowledge box\")\n",
    "print_results(\"Full text search\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad6dab",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "Full text search has its limitations, so let's try our semantic search and compare the results from different models\n",
    "\n",
    "To perform these searches we need to encode our query and pass it to the search function with the `vector` argument.\n",
    "The results will be retrieved in order from more to less similar (based on cosine similarity).\n",
    "Note that you can define a threshold (`min_score`) so that the serach will only return results with similarity higher than a certain value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9797adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY:  create a new knowledge box\n",
      "\t***UNICOXDER RESULTS***\n",
      "Function name: get_or_create -- Similarity score: 0.4122781753540039\n",
      "Function name: create_knowledge_box -- Similarity score: 0.38341182470321655\n",
      "Function name: get_kb -- Similarity score: 0.35511818528175354\n",
      "Function name: search -- Similarity score: 0.3201015889644623\n",
      "Function name: get_entities -- Similarity score: 0.3016570508480072\n",
      "-----------\n",
      "\t***T5 RESULTS***\n",
      "Function name: create_knowledge_box -- Similarity score: 0.6352006196975708\n",
      "Function name: get_kb -- Similarity score: 0.4774329662322998\n",
      "Function name: get_labels -- Similarity score: 0.4565504193305969\n",
      "Function name: get_entities -- Similarity score: 0.4362731873989105\n",
      "Function name: async_length -- Similarity score: 0.4227059781551361\n",
      "Function name: get_or_create -- Similarity score: 0.35420358180999756\n",
      "-----------\n",
      "\t***DISTILROBERTA RESULTS***\n",
      "Function name: create_knowledge_box -- Similarity score: 0.612922191619873\n",
      "Function name: get_or_create -- Similarity score: 0.4198019206523895\n",
      "Function name: create_resource -- Similarity score: 0.3761809468269348\n",
      "-----------\n",
      "\t***BERT RESULTS***\n",
      "Function name: create_knowledge_box -- Similarity score: 0.612922191619873\n",
      "Function name: get_or_create -- Similarity score: 0.4198019206523895\n",
      "Function name: create_resource -- Similarity score: 0.3761809468269348\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "query =[\"create a new knowledge box\"]\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.3)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0].tolist(), \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.3)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0].tolist(), \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.3)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b7d117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY:  Upload vectors\n",
      "\t***UNICOXDER RESULTS***\n",
      "Function name: list_vectorset -- Similarity score: 0.33021214604377747\n",
      "-----------\n",
      "\t***T5 RESULTS***\n",
      "Function name: async_upload -- Similarity score: 0.5734764337539673\n",
      "Function name: upload -- Similarity score: 0.5514383912086487\n",
      "-----------\n",
      "\t***DISTILROBERTA RESULTS***\n",
      "Function name: async_upload -- Similarity score: 0.5523496866226196\n",
      "Function name: upload -- Similarity score: 0.5517340302467346\n",
      "Function name: async_set_vectorset -- Similarity score: 0.47345882654190063\n",
      "Function name: set_vectorset -- Similarity score: 0.46942102909088135\n",
      "Function name: async_del_vectorset -- Similarity score: 0.4166334569454193\n",
      "-----------\n",
      "\t***BERT RESULTS***\n",
      "Function name: async_upload -- Similarity score: 0.5523496866226196\n",
      "Function name: upload -- Similarity score: 0.5517340302467346\n",
      "Function name: async_set_vectorset -- Similarity score: 0.47345882654190063\n",
      "Function name: set_vectorset -- Similarity score: 0.46942102909088135\n",
      "Function name: async_del_vectorset -- Similarity score: 0.4166334569454193\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "query =[\"Upload vectors\"]\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.4)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0].tolist(), \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.4)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0].tolist(), \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.4)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ae668d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY:  create labels\n",
      "\t***UNICOXDER RESULTS***\n",
      "Function name: list_vectorset -- Similarity score: 0.33020952343940735\n",
      "-----------\n",
      "\t***T5 RESULTS***\n",
      "Function name: set_labels -- Similarity score: 0.5127634406089783\n",
      "Function name: get_labels -- Similarity score: 0.4446571171283722\n",
      "-----------\n",
      "\t***DISTILROBERTA RESULTS***\n",
      "Function name: set_labels -- Similarity score: 0.6097429394721985\n",
      "Function name: get_labels -- Similarity score: 0.43312472105026245\n",
      "-----------\n",
      "\t***BERT RESULTS***\n",
      "Function name: set_labels -- Similarity score: 0.6097429394721985\n",
      "Function name: get_labels -- Similarity score: 0.43312472105026245\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "query =[\"create labels\"]\n",
    "\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.4)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0].tolist(), \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.4)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0].tolist(), \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.4)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9b5e7",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As we can see the models with better overall results are **T5**,**BERT**, and **DISTILROBERTA**.\n",
    "And as a curiosity, even though the **BERT** and **DISTILROBERTA** were supposed to be different, their results are exactly the same\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
